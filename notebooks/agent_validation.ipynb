{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Validation Notebook\n",
    "\n",
    "This notebook validates the functionality of all agents in the AI Load Predictor system.\n",
    "\n",
    "## Agents to Test:\n",
    "1. Data Processing Agent\n",
    "2. EDA Agent\n",
    "3. Modeling Agent\n",
    "4. Model Verification Agent\n",
    "5. Model Deployment Agent\n",
    "6. Forecasting Agent\n",
    "7. Visualization Agent\n",
    "8. Coordinating Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/gonzalf1/git/AILoadPredictor2\n",
      "Current working directory: /Users/gonzalf1/git/AILoadPredictor2/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataProcessingAgent imported successfully\n",
      "✅ DataProcessingAgent initialized successfully\n",
      "✅ Data loaded from file: (8760, 5)\n",
      "Columns: ['timestamp', 'load', 'temperature', 'humidity', 'is_holiday']\n",
      "✅ Data processed successfully: (8760, 14)\n",
      "Processed columns: ['timestamp', 'load', 'hour', 'day', 'day_of_week', 'month', 'year', 'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos', 'is_weekend']\n"
     ]
    }
   ],
   "source": [
    "# Test Data Processing Agent\n",
    "try:\n",
    "    from agents.data_processing_agent import DataProcessingAgent\n",
    "    \n",
    "    print(\"✅ DataProcessingAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    data_agent = DataProcessingAgent()\n",
    "    print(\"✅ DataProcessingAgent initialized successfully\")\n",
    "    \n",
    "    # Test with sample data file\n",
    "    sample_data_path = '../data/sample_hourly_load.csv'\n",
    "    if os.path.exists(sample_data_path):\n",
    "        with open(sample_data_path, 'rb') as f:\n",
    "            test_data = data_agent.ingest_from_file(f)\n",
    "        print(f\"✅ Data loaded from file: {test_data.shape}\")\n",
    "        print(f\"Columns: {list(test_data.columns)}\")\n",
    "    else:\n",
    "        # Create sample data for testing\n",
    "        dates = pd.date_range('2023-01-01', periods=100, freq='H')\n",
    "        test_data = pd.DataFrame({\n",
    "            'timestamp': dates,\n",
    "            'load': np.random.normal(100, 20, 100),\n",
    "            'temperature': np.random.normal(20, 5, 100)\n",
    "        })\n",
    "        print(\"✅ Sample data created for testing\")\n",
    "    \n",
    "    # Test data processing\n",
    "    processed_data = data_agent.process(\n",
    "        data=test_data,\n",
    "        timestamp_col='timestamp',\n",
    "        target_col='load',\n",
    "        freq='H'\n",
    "    )\n",
    "    print(f\"✅ Data processed successfully: {processed_data.shape}\")\n",
    "    print(f\"Processed columns: {list(processed_data.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ DataProcessingAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EDAAgent imported successfully\n",
      "✅ EDAAgent initialized successfully\n",
      "✅ EDA performed successfully\n",
      "EDA results keys: ['descriptive_stats', 'time_series_plot', 'seasonality_plot', 'autocorrelation_plot', 'insights']\n",
      "✅ Time series plot generated\n",
      "✅ Descriptive statistics generated\n",
      "  Statistic        Value\n",
      "0     count  8760.000000\n",
      "1      mean  9573.999290\n",
      "2       std  2683.926395\n",
      "3       min  2369.582584\n",
      "4       25%  7584.125778\n"
     ]
    }
   ],
   "source": [
    "# Test EDA Agent\n",
    "try:\n",
    "    from agents.eda_agent import EDAAgent\n",
    "    \n",
    "    print(\"✅ EDAAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    eda_agent = EDAAgent()\n",
    "    print(\"✅ EDAAgent initialized successfully\")\n",
    "    \n",
    "    # Use processed data from previous step\n",
    "    if 'processed_data' in locals():\n",
    "        eda_results = eda_agent.analyze(\n",
    "            data=processed_data,\n",
    "            target_col='load',\n",
    "            timestamp_col='timestamp'\n",
    "        )\n",
    "        print(\"✅ EDA performed successfully\")\n",
    "        print(f\"EDA results keys: {list(eda_results.keys())}\")\n",
    "        \n",
    "        # Check if plots were generated\n",
    "        if 'time_series_plot' in eda_results:\n",
    "            print(\"✅ Time series plot generated\")\n",
    "        if 'descriptive_stats' in eda_results:\n",
    "            print(\"✅ Descriptive statistics generated\")\n",
    "            print(eda_results['descriptive_stats'].head())\n",
    "    else:\n",
    "        print(\"❌ No processed data available for EDA\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ EDAAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Modeling Agent\n",
    "try:\n",
    "    from agents.modeling_agent import ModelingAgent\n",
    "    \n",
    "    print(\"✅ ModelingAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    modeling_agent = ModelingAgent()\n",
    "    print(\"✅ ModelingAgent initialized successfully\")\n",
    "    \n",
    "    # Use processed data from previous step\n",
    "    if 'processed_data' in locals():\n",
    "        # Test model training with a simple set of models\n",
    "        models_to_train = ['RandomForest', 'LinearRegression']\n",
    "        config = {\n",
    "            'train_size': 0.8,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        trained_models = modeling_agent.train(\n",
    "            data=processed_data,\n",
    "            target_col='load',\n",
    "            timestamp_col='timestamp',\n",
    "            models=models_to_train,\n",
    "            config=config\n",
    "        )\n",
    "        print(\"✅ Models trained successfully\")\n",
    "        print(f\"Trained models: {list(trained_models['models'].keys())}\")\n",
    "        print(f\"Best model: {trained_models['best_model']}\")\n",
    "        \n",
    "        # Display metrics\n",
    "        if 'metrics' in trained_models:\n",
    "            print(\"✅ Model metrics generated\")\n",
    "            for model_name, metrics in trained_models['metrics'].items():\n",
    "                print(f\"{model_name}: MAPE={metrics.get('mape', 'N/A'):.2f}%, R2={metrics.get('r2', 'N/A'):.3f}\")\n",
    "    else:\n",
    "        print(\"❌ No processed data available for modeling\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ModelingAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Verification Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Verification Agent\n",
    "try:\n",
    "    from agents.model_verification_agent import ModelVerificationAgent\n",
    "    \n",
    "    print(\"✅ ModelVerificationAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    verification_agent = ModelVerificationAgent()\n",
    "    print(\"✅ ModelVerificationAgent initialized successfully\")\n",
    "    \n",
    "    # Use trained models from previous step\n",
    "    if 'trained_models' in locals():\n",
    "        # Test model verification\n",
    "        verification_results = verification_agent.verify_models(\n",
    "            models=trained_models['models'],\n",
    "            data=processed_data,\n",
    "            target_col='load',\n",
    "            timestamp_col='timestamp'\n",
    "        )\n",
    "        print(\"✅ Model verification completed successfully\")\n",
    "        print(f\"Verification results keys: {list(verification_results.keys())}\")\n",
    "        \n",
    "        # Check verification metrics\n",
    "        if 'verification_metrics' in verification_results:\n",
    "            print(\"✅ Verification metrics generated\")\n",
    "    else:\n",
    "        print(\"❌ No trained models available for verification\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ModelVerificationAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Forecasting Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Forecasting Agent\n",
    "try:\n",
    "    from agents.forecasting_agent import ForecastingAgent\n",
    "    \n",
    "    print(\"✅ ForecastingAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    forecasting_agent = ForecastingAgent()\n",
    "    print(\"✅ ForecastingAgent initialized successfully\")\n",
    "    \n",
    "    # Use trained models from previous step\n",
    "    if 'trained_models' in locals():\n",
    "        # Get the best model\n",
    "        best_model_name = trained_models['best_model']\n",
    "        best_model_info = trained_models['models'][best_model_name]\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts = forecasting_agent.generate_forecasts(\n",
    "            data=processed_data,\n",
    "            model_info=best_model_info,\n",
    "            horizon=24,  # 24-hour forecast\n",
    "            confidence_interval=0.95\n",
    "        )\n",
    "        print(\"✅ Forecasts generated successfully\")\n",
    "        print(f\"Forecast results keys: {list(forecasts.keys())}\")\n",
    "        \n",
    "        # Check forecast data\n",
    "        if 'forecast_data' in forecasts:\n",
    "            forecast_df = forecasts['forecast_data']\n",
    "            print(f\"✅ Forecast data shape: {forecast_df.shape}\")\n",
    "            print(f\"Forecast columns: {list(forecast_df.columns)}\")\n",
    "    else:\n",
    "        print(\"❌ No trained models available for forecasting\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ForecastingAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Visualization Agent\n",
    "try:\n",
    "    from agents.visualization_agent import VisualizationAgent\n",
    "    \n",
    "    print(\"✅ VisualizationAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    viz_agent = VisualizationAgent()\n",
    "    print(\"✅ VisualizationAgent initialized successfully\")\n",
    "    \n",
    "    # Test basic visualization creation\n",
    "    if 'processed_data' in locals():\n",
    "        # Create time series plot\n",
    "        time_series_plot = viz_agent.create_time_series_plot(\n",
    "            data=processed_data,\n",
    "            timestamp_col='timestamp',\n",
    "            target_col='load'\n",
    "        )\n",
    "        print(\"✅ Time series plot created successfully\")\n",
    "        \n",
    "        # Test forecast visualization if forecasts are available\n",
    "        if 'forecasts' in locals():\n",
    "            forecast_plot = viz_agent.create_forecast_plot(\n",
    "                historical_data=processed_data,\n",
    "                forecast_data=forecasts['forecast_data'],\n",
    "                timestamp_col='timestamp',\n",
    "                target_col='load'\n",
    "            )\n",
    "            print(\"✅ Forecast plot created successfully\")\n",
    "    else:\n",
    "        print(\"❌ No data available for visualization\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ VisualizationAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Deployment Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Deployment Agent\n",
    "try:\n",
    "    from agents.model_deployment_agent import ModelDeploymentAgent\n",
    "    \n",
    "    print(\"✅ ModelDeploymentAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    deployment_agent = ModelDeploymentAgent()\n",
    "    print(\"✅ ModelDeploymentAgent initialized successfully\")\n",
    "    \n",
    "    # Test model deployment (usually involves saving/loading models)\n",
    "    if 'trained_models' in locals():\n",
    "        best_model_name = trained_models['best_model']\n",
    "        best_model_info = trained_models['models'][best_model_name]\n",
    "        \n",
    "        # Test model preparation for deployment\n",
    "        deployment_package = deployment_agent.prepare_model_for_deployment(\n",
    "            model_info=best_model_info,\n",
    "            model_name=best_model_name,\n",
    "            metadata={\n",
    "                'model_type': best_model_name,\n",
    "                'training_date': pd.Timestamp.now().isoformat(),\n",
    "                'performance_metrics': trained_models['metrics'][best_model_name]\n",
    "            }\n",
    "        )\n",
    "        print(\"✅ Model prepared for deployment successfully\")\n",
    "        print(f\"Deployment package keys: {list(deployment_package.keys())}\")\n",
    "    else:\n",
    "        print(\"❌ No trained models available for deployment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ModelDeploymentAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Coordinating Agent Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Coordinating Agent\n",
    "try:\n",
    "    from agents.coordinating_agent import CoordinatingAgent\n",
    "    \n",
    "    print(\"✅ CoordinatingAgent imported successfully\")\n",
    "    \n",
    "    # Initialize the agent\n",
    "    coordinator = CoordinatingAgent()\n",
    "    print(\"✅ CoordinatingAgent initialized successfully\")\n",
    "    \n",
    "    # Test the full workflow coordination\n",
    "    print(\"Testing full workflow coordination...\")\n",
    "    \n",
    "    # Check if all sub-agents are initialized\n",
    "    sub_agents = [\n",
    "        'data_processing_agent',\n",
    "        'eda_agent', \n",
    "        'modeling_agent',\n",
    "        'model_verification_agent',\n",
    "        'model_deployment_agent',\n",
    "        'forecasting_agent',\n",
    "        'visualization_agent'\n",
    "    ]\n",
    "    \n",
    "    for agent_name in sub_agents:\n",
    "        if hasattr(coordinator, agent_name):\n",
    "            print(f\"✅ {agent_name} initialized in coordinator\")\n",
    "        else:\n",
    "            print(f\"❌ {agent_name} missing in coordinator\")\n",
    "    \n",
    "    # Check workflow state\n",
    "    print(f\"✅ Workflow state initialized with keys: {list(coordinator.state.keys())}\")\n",
    "    \n",
    "    # Test a simple coordination method\n",
    "    if hasattr(coordinator, 'process_data') and 'test_data' in locals():\n",
    "        coordinated_result = coordinator.process_data(\n",
    "            data=test_data,\n",
    "            timestamp_col='timestamp',\n",
    "            target_col='load',\n",
    "            freq='H'\n",
    "        )\n",
    "        print(\"✅ Coordinated data processing successful\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ CoordinatingAgent failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration Test - Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full integration test using the coordinating agent\n",
    "print(\"=\" * 50)\n",
    "print(\"FULL INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create sample data for the full pipeline test\n",
    "    dates = pd.date_range('2023-01-01', periods=168, freq='H')  # 1 week of hourly data\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create realistic load pattern\n",
    "    base_load = 100\n",
    "    daily_pattern = 20 * np.sin(2 * np.pi * np.arange(168) / 24)\n",
    "    weekly_pattern = 10 * np.sin(2 * np.pi * np.arange(168) / (24 * 7))\n",
    "    noise = np.random.normal(0, 5, 168)\n",
    "    load = base_load + daily_pattern + weekly_pattern + noise\n",
    "    \n",
    "    pipeline_data = pd.DataFrame({\n",
    "        'timestamp': dates,\n",
    "        'load': load,\n",
    "        'temperature': 20 + 5 * np.sin(2 * np.pi * np.arange(168) / 24) + np.random.normal(0, 2, 168)\n",
    "    })\n",
    "    \n",
    "    print(f\"✅ Integration test data created: {pipeline_data.shape}\")\n",
    "    \n",
    "    # Initialize coordinator\n",
    "    if 'coordinator' not in locals():\n",
    "        coordinator = CoordinatingAgent()\n",
    "    \n",
    "    # Run full pipeline\n",
    "    print(\"\\n1. Processing data...\")\n",
    "    processed = coordinator.process_data(\n",
    "        data=pipeline_data,\n",
    "        timestamp_col='timestamp',\n",
    "        target_col='load',\n",
    "        freq='H'\n",
    "    )\n",
    "    coordinator.state['processed_data'] = processed\n",
    "    print(f\"   ✅ Data processed: {processed.shape}\")\n",
    "    \n",
    "    print(\"\\n2. Performing EDA...\")\n",
    "    eda_results = coordinator.perform_eda(\n",
    "        data=processed,\n",
    "        target_col='load',\n",
    "        timestamp_col='timestamp'\n",
    "    )\n",
    "    coordinator.state['eda_results'] = eda_results\n",
    "    print(f\"   ✅ EDA completed with {len(eda_results)} result types\")\n",
    "    \n",
    "    print(\"\\n3. Training models...\")\n",
    "    models = coordinator.train_models(\n",
    "        data=processed,\n",
    "        target_col='load',\n",
    "        timestamp_col='timestamp',\n",
    "        models=['RandomForest', 'LinearRegression'],\n",
    "        config={'train_size': 0.8, 'random_state': 42}\n",
    "    )\n",
    "    coordinator.state['trained_models'] = models\n",
    "    coordinator.state['selected_model'] = models['best_model']\n",
    "    print(f\"   ✅ Models trained. Best model: {models['best_model']}\")\n",
    "    \n",
    "    print(\"\\n4. Generating forecasts...\")\n",
    "    forecasts = coordinator.generate_forecasts(\n",
    "        data=processed,\n",
    "        model_name=models['best_model'],\n",
    "        horizon=24\n",
    "    )\n",
    "    coordinator.state['forecasts'] = forecasts\n",
    "    print(f\"   ✅ Forecasts generated for 24 periods\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"INTEGRATION TEST COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nPipeline Summary:\")\n",
    "    print(f\"- Input data: {pipeline_data.shape[0]} records\")\n",
    "    print(f\"- Processed data: {processed.shape[0]} records, {processed.shape[1]} features\")\n",
    "    print(f\"- Models trained: {len(models['models'])}\")\n",
    "    print(f\"- Best model: {models['best_model']}\")\n",
    "    print(f\"- Forecast horizon: 24 periods\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Integration test failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENT VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "validation_results = {\n",
    "    'DataProcessingAgent': '✅' if 'data_agent' in locals() else '❌',\n",
    "    'EDAAgent': '✅' if 'eda_agent' in locals() else '❌',\n",
    "    'ModelingAgent': '✅' if 'modeling_agent' in locals() else '❌',\n",
    "    'ModelVerificationAgent': '✅' if 'verification_agent' in locals() else '❌',\n",
    "    'ForecastingAgent': '✅' if 'forecasting_agent' in locals() else '❌',\n",
    "    'VisualizationAgent': '✅' if 'viz_agent' in locals() else '❌',\n",
    "    'ModelDeploymentAgent': '✅' if 'deployment_agent' in locals() else '❌',\n",
    "    'CoordinatingAgent': '✅' if 'coordinator' in locals() else '❌'\n",
    "}\n",
    "\n",
    "for agent, status in validation_results.items():\n",
    "    print(f\"{agent:<25} {status}\")\n",
    "\n",
    "successful_agents = sum(1 for status in validation_results.values() if status == '✅')\n",
    "total_agents = len(validation_results)\n",
    "\n",
    "print(f\"\\nValidation Results: {successful_agents}/{total_agents} agents validated successfully\")\n",
    "\n",
    "if successful_agents == total_agents:\n",
    "    print(\"🎉 ALL AGENTS VALIDATED SUCCESSFULLY!\")\n",
    "else:\n",
    "    failed_agents = [agent for agent, status in validation_results.items() if status == '❌']\n",
    "    print(f\"⚠️  Failed agents: {', '.join(failed_agents)}\")\n",
    "    \n",
    "print(\"\\nNext steps:\")\n",
    "print(\"- Review any failed agent validations above\")\n",
    "print(\"- Check import paths and dependencies\")\n",
    "print(\"- Ensure all required methods are implemented in each agent\")\n",
    "print(\"- Test the agents with real data in the main application\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
